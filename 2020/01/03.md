# Hive 설정값 

## hive.exec.parallel
이 설정은 작업이 다른 테이블 간의 조인이라면 각 데이터를 읽어오는 것을 병렬로 실행할 수 있게 한다. 
파일 이동 단계에서도 동시에 처리할 수 있게 한다. 

**tez 잡의 경우 DAG를 동시에 사용하는 문제로 오류가 발생할 수 있다.**
**어떤 방식으로 해도 에러가 발생할 가능성이 있음**

```
-- 기본값은 false
set hive.exec.parallel=true;
set hive.exec.parallel.thread.number=8;
```

## hive.tez.auto.reducer.parallelism

+ 46G의 데이터를 이용하여 select count처리
+ tez.grouping.max 기본은 1G
+ reducer.byte 기본은 256MB


매퍼, reducer
    init, running
46, 184, 184
46, 368, 46
46, 736, 92
46, 368, 184

hive.tez.auto.reducer.parallelism
hive.exec.reducer.byte.per.reducer
hive.tez.max.partition.factor
hive.tez.min.partition.factor

FALSE, 256
TRUE, 256, 2, 0.25
TRUE, 128, 2, 0.25
TRUE, 128, 1, 0.5


# 최종 파일 작업시간
+ 파일 쓰기 위치, 150G 데이터를 이용
  + s3에 저장: 1351.4초
  + HDFS에 저장: 1096.8초 
+ 파일 머지
+ 적절한 개수의 파일 생성 
  + 너무 작은 사이즈의 파일이나, 많은 개수의 파일은 오류가 발생할 수 있음 
 


# 하이브 조인

+ 셔플 조인
  + 매퍼가 각 테이블을 읽고, 조인키를 기준으로 셔플하여 리듀서에서 조인 
+ 맵 조인
  + 작은 사이즈의 테이블을 메모리에 올려서 조인 
+ SMB 조인 
  + 버켓팅된 데이터를 이용하여 버켓 해쉬값으로 조인 


# 하이브 Builtin UDF
진수 변환을 해주는 `conv` 함수 

```
select conv('A', 16, 10);
10
```

# 하이브 explain
+ explain의 width는 파일 사이즈 
